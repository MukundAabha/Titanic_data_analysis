{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic survival - optimising models with grid search and random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hide warnings (to keep notebook tidy; do not usually do this)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Import machine learning methods\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/t_data/processed_data.csv')\n",
    "# Make all data 'float' type\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Passengerid (axis=1 indicates we are removing a column rather than a row)\n",
    "# We drop passenger ID as it is not original data\n",
    "\n",
    "data.drop('PassengerId', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide into X (features) and y (labels)\n",
    "X = data.drop('Survived',axis=1) # X = all 'data' except the 'survived' column\n",
    "y = data['Survived'] # y = 'survived' column from 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise a new scaling object for normalising input data\n",
    "sc = StandardScaler() \n",
    "\n",
    "# Set up the scaler just on the training set\n",
    "sc.fit(X)\n",
    "\n",
    "# Apply the scaler to the X data\n",
    "X_std=sc.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid serach is a good method so long as the number of paramater combinations is not too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.1, 1, 10],\n",
    "              'class_weight': [{0:0.5, 1:0.5},{0:0.38, 1:0.62}]}\n",
    "\n",
    "# Class weight is defined as a dictionary with class label and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above paraemter grid we have 2 * 4 * 2 parameter combinations = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search with defined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Define grid search to use 5 k-fold validation, and use 'f1' for accuracy\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "# Run grid search\n",
    "grid_search.fit(X_std, y); #';' suppresses printed output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show grid search performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance (f1):\n",
      "0.7355099445362381\n",
      "Best parameters:\n",
      "{'C': 0.1, 'class_weight': {0: 0.38, 1: 0.62}, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "# show best performance and parameters\n",
    "# If best parameters are at the extremes of the searches then extend the range\n",
    "\n",
    "print ('Best performance (f1):')\n",
    "print (grid_search.best_score_)\n",
    "print ('Best parameters:')\n",
    "print (grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight={0: 0.38, 1: 0.62}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_penalty param_C  param_class_weight  mean_test_score  rank_test_score\n",
      "0             l1    0.01    {0: 0.5, 1: 0.5}         0.000000               15\n",
      "1             l2    0.01    {0: 0.5, 1: 0.5}         0.714713               13\n",
      "2             l1    0.01  {0: 0.38, 1: 0.62}         0.000000               15\n",
      "3             l2    0.01  {0: 0.38, 1: 0.62}         0.730961                2\n",
      "4             l1     0.1    {0: 0.5, 1: 0.5}         0.709479               14\n",
      "5             l2     0.1    {0: 0.5, 1: 0.5}         0.722657                8\n",
      "6             l1     0.1  {0: 0.38, 1: 0.62}         0.724712                6\n",
      "7             l2     0.1  {0: 0.38, 1: 0.62}         0.735510                1\n",
      "8             l1       1    {0: 0.5, 1: 0.5}         0.721540                9\n",
      "9             l2       1    {0: 0.5, 1: 0.5}         0.720458               11\n",
      "10            l1       1  {0: 0.38, 1: 0.62}         0.723316                7\n",
      "11            l2       1  {0: 0.38, 1: 0.62}         0.729697                3\n",
      "12            l1      10    {0: 0.5, 1: 0.5}         0.720458               11\n",
      "13            l2      10    {0: 0.5, 1: 0.5}         0.720487               10\n",
      "14            l1      10  {0: 0.38, 1: 0.62}         0.727679                4\n",
      "15            l2      10  {0: 0.38, 1: 0.62}         0.727679                4\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "cols_to_show = ['param_penalty','param_C', 'param_class_weight',\n",
    "                'mean_test_score','rank_test_score' ]\n",
    "print(results[cols_to_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the results, it is worth noting the range of results. Tou may then consider whether it is worth refining the grid search to focus on a narrower area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Random search is very similar to grid search, but randomly selects combinations of parameters to test, with the maximum number of tests given by the `n_iter` argument.\n",
    "\n",
    "As we've been through the process with grid search, we'll put all our code together here, but note the larger number of parameters defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performance (f1):\n",
      "0.7355099445362381\n",
      "Best parameters:\n",
      "{'penalty': 'l2', 'max_iter': 100, 'class_weight': {0: 0.38, 1: 0.62}, 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/michael/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import GridSearch\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define paraemter grid and maximum number of tests\n",
    "\n",
    "param_grid = {'penalty': ['l1', 'l2'],\n",
    "              'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
    "              'class_weight': [{0:0.5, 1:0.5},\n",
    "                               {0:0.38, 1:0.62},\n",
    "                               {0:0.62, 1:0.38}],\n",
    "              'max_iter': [30, 100, 300, 1000]}\n",
    "\n",
    "n_iter_search = 50\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Set up random search\n",
    "random_search = RandomizedSearchCV(model, param_grid, cv=5,\n",
    "                           n_iter=n_iter_search, scoring='f1')\n",
    "\n",
    "# Run grid search\n",
    "random_search.fit(X_std, y); #';' suppresses printed output\n",
    "\n",
    "# Get and print output\n",
    "print ('Best performance (f1):')\n",
    "print (random_search.best_score_)\n",
    "print ('Best parameters:')\n",
    "print (random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   param_penalty param_C  param_class_weight  mean_test_score  rank_test_score\n",
      "0             l1       3    {0: 0.5, 1: 0.5}         0.721539               13\n",
      "1             l2    0.03    {0: 0.5, 1: 0.5}         0.731564                2\n",
      "2             l2     0.3  {0: 0.62, 1: 0.38}         0.714191               21\n",
      "3             l1       3  {0: 0.62, 1: 0.38}         0.704302               33\n",
      "4             l1      10    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "5             l1     0.3    {0: 0.5, 1: 0.5}         0.721433               14\n",
      "6             l1     0.1  {0: 0.38, 1: 0.62}         0.724712                7\n",
      "7             l1     0.1  {0: 0.38, 1: 0.62}         0.724712                7\n",
      "8             l2      10  {0: 0.62, 1: 0.38}         0.703537               36\n",
      "9             l2    0.01  {0: 0.62, 1: 0.38}         0.650990               43\n",
      "10            l2      10  {0: 0.38, 1: 0.62}         0.727679                6\n",
      "11            l2      10    {0: 0.5, 1: 0.5}         0.720487               15\n",
      "12            l1       1  {0: 0.62, 1: 0.38}         0.704254               35\n",
      "13            l2    0.03  {0: 0.62, 1: 0.38}         0.692330               41\n",
      "14            l1    0.01    {0: 0.5, 1: 0.5}         0.000000               46\n",
      "15            l1     0.1    {0: 0.5, 1: 0.5}         0.709479               25\n",
      "16            l1    0.01  {0: 0.62, 1: 0.38}         0.000000               46\n",
      "17            l2     0.3  {0: 0.62, 1: 0.38}         0.714191               21\n",
      "18            l1    0.01  {0: 0.38, 1: 0.62}         0.000000               46\n",
      "19            l1       1    {0: 0.5, 1: 0.5}         0.721540               10\n",
      "20            l1     0.3  {0: 0.38, 1: 0.62}         0.722912                9\n",
      "21            l2     0.3  {0: 0.38, 1: 0.62}         0.730898                4\n",
      "22            l1    0.01  {0: 0.38, 1: 0.62}         0.000000               46\n",
      "23            l1    0.01  {0: 0.62, 1: 0.38}         0.000000               46\n",
      "24            l1       1    {0: 0.5, 1: 0.5}         0.721540               10\n",
      "25            l1      10    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "26            l2     0.1  {0: 0.62, 1: 0.38}         0.711792               23\n",
      "27            l1     0.1    {0: 0.5, 1: 0.5}         0.709479               25\n",
      "28            l2    0.01  {0: 0.38, 1: 0.62}         0.730961                3\n",
      "29            l1     0.3  {0: 0.62, 1: 0.38}         0.695724               40\n",
      "30            l1    0.03  {0: 0.38, 1: 0.62}         0.709217               27\n",
      "31            l2       1  {0: 0.38, 1: 0.62}         0.729697                5\n",
      "32            l2       3    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "33            l1    0.03  {0: 0.38, 1: 0.62}         0.709217               27\n",
      "34            l2    0.03  {0: 0.62, 1: 0.38}         0.692330               41\n",
      "35            l1       3  {0: 0.62, 1: 0.38}         0.704302               33\n",
      "36            l2     0.1  {0: 0.38, 1: 0.62}         0.735510                1\n",
      "37            l1    0.03    {0: 0.5, 1: 0.5}         0.709217               27\n",
      "38            l1      10  {0: 0.62, 1: 0.38}         0.703537               36\n",
      "39            l1    0.03  {0: 0.38, 1: 0.62}         0.709217               27\n",
      "40            l2       1    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "41            l1      10  {0: 0.62, 1: 0.38}         0.703537               36\n",
      "42            l2       3  {0: 0.62, 1: 0.38}         0.702510               39\n",
      "43            l2    0.01  {0: 0.62, 1: 0.38}         0.650990               43\n",
      "44            l2    0.01  {0: 0.62, 1: 0.38}         0.650990               43\n",
      "45            l2       1  {0: 0.62, 1: 0.38}         0.706706               31\n",
      "46            l2       1    {0: 0.5, 1: 0.5}         0.720458               16\n",
      "47            l1       1    {0: 0.5, 1: 0.5}         0.721540               10\n",
      "48            l2       1  {0: 0.62, 1: 0.38}         0.706706               31\n",
      "49            l2     0.1  {0: 0.62, 1: 0.38}         0.711792               23\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame(random_search.cv_results_)\n",
    "cols_to_show = ['param_penalty','param_C', 'param_class_weight',\n",
    "                'mean_test_score','rank_test_score' ]\n",
    "print(results[cols_to_show])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
